# Introduction {#ch:intro}

Exploratory data analysis (EDA) is a vital element of the modern 
statistical workflow - it is an analyst’s first pass at 
understanding their data; revealing all it’s messes and 
uncovering hidden insights [@Tukey1977-pn; @Grolemund2017-uc]. 
It is an iterative process involving computation and visualization,
leading to new hypotheses that can be tested and formalised using 
statistical modelling. As datasets grow in complexity and become
increasingly heterogeneous and multidimensional, 
the use of EDA becomes vital to ensure the integrity and quality of analysis 
outputs. This is certainly true in high-throughput biological 
data sceince, where constraints on computation time and memory, in addition
to the analyst's time, results in EDA becoming increasingly difficult and 
neglected. 

This thesis develops tools and frameworks to perform EDA as part of the
biological data science workflow...  



## A grammar for genomic data analysis

The approach taken by the suite of software packages collectively known as the 
*tidyverse*  is an attempt to formalise aspects of the EDA process in the R
programming language under a single semantic known as *tidy data* 
[@baser; @tidyverse; @Wickham2014-jc]. Simply put, a *tidy data* set is a 
rectangular table where each row of the table corresponds to an  observation, 
each column corresponds to a variable and each cell a value. There is a 
surprisingly large amount of utility that can be achieved with this definition. 
By having each column representing a variable, variables in the data can be mapped
to graphical aesthetics of plots. This paradigm enables the grammar of graphics 
as implemented by *ggplot2* [@Wickham2016-gz; @Wilkinson2005-kq]. User interfaces
as implemented by *tidyverse*, and in particular the *dplyr* package, are *fluent*; 
they form a domain specific language (DSL) that gives users a mental model 
for performing and composing common data transformation tasks 
[@Wickham2017-dplyr; @FowlerFluent].

It is unclear whether the *fluent* interfaces as implemented using the
*tidy data* framework can be more generally applied and useful
in fields such as high-throughput biology where domain specific semantics are 
required. This is particularly true in the *Bioconductor* ecosystem, where much 
thought has gone into the design of data structures that enable interoperability
between different tools, biological assays and analysis goals [@Huber2015-ei].

Chapter \@ref(ch:plyranges) shows that the *tidy data* semantic is applicable
to range-based genomics data and develops a *fluent* interface to transforming
it called *plyranges*. The software provides a framework to an assist
an analyst to compose queries on genomics datasets. This chapter has been 
published in Genome Biology [@Lee2019].

## Integration and representation of genomic data structures 

- talking about chapters 3 and 4 here
- having the grammar doesn't impair interoperability, in fact we show it
can be used to glue two different approches
- the long form representation can be taken even further... 
- recasting EDA problems as search, we want to find regions measured along the
genome that display a characteristic of interest, and then link that to raw 
data plots.


## Visual analytics for dimension reduction workflows


- talking about chapter 5
- taking a step back in the last chapter, have been focused on data wrangling
but am now looking the integration of vis and models
- focussed on a common part of EDA as applied to transcriptomics, dimension
reduction workflows
- especially non-linear dr as that has gotten extremely popular
- combining with the tour, we can grasp the trade-off between global and
local views of the data
- user interaction provides ability to dissect the quality of a DR, and
perform cluster oriented tasks




