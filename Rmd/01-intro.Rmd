# Introduction {#ch:intro}

Exploratory data analysis (EDA) is a vital element of the modern 
statistical workflow - it is an analyst’s first pass at 
understanding their data; revealing all it’s messes and 
uncovering hidden insights [@Tukey1977-pn; @Grolemund2017-uc]. 
It is an iterative process involving computation and visualization,
leading to new hypotheses that can be tested and formalised using 
statistical modelling (figure \@ref(fig:wflow-cycle)). As datasets grow in complexity and become
increasingly heterogeneous and multidimensional, 
the use of EDA becomes vital to ensure the integrity and quality of analysis 
outputs. This is certainly true in high-throughput biological 
data science, where constraints on computation time and memory, in addition
to the analyst's time, makes EDA difficult and neglected, which impacts the robustness and reliability of any downstream analysis.  

(ref:wflow-cycle) An idealised model of the biological data science workflow (adapted from  @Grolemund2017-uc). We begin with data generated from one or more biological assay(s) corresponding to a research hypothesis or question. Our primary focus is on data generated from bulk assays that measure gene expression (RNA-seq), genetic variation (DNA-seq), and gene regulation (ChIP-seq, ATAC-seq). Throughout this process, we need computational tools to gain insight into the biology under study and communicate our analysis in a reproducible manner. 

(ref:wflow-wrangle) In the wrangle phase of the workflow, data from an assay is imported into a programming language. It is then tidied into a new representation that should capture the biological semantics of the measurements. Following this, the representation can be transformed to generate new summaries. 

(ref:wflow-integrate) Data from multiple assays can be combined together using modelling and transformations. Data and model results can be combined, tidied and transformed to have a common representation across different granularities of the genome.

(ref:wflow-explore) Visualisation is a tool for making sense of models. Here we explore, how well a model has captured the structure within the data using interactive graphics.  

```{r wflow-cycle, fig.cap="(ref:wflow-cycle)"}
knitr::include_graphics(here::here("img", "wflow-thesis-cycle.png"))
```


This thesis focuses on core aspects of EDA as part of a biological data
science workflow: wrangling, integration and visualisation, with a focus 
on applications to genomics and transcriptomics. To begin we discuss wrangling
biological data using a coherent representation and programming interface 
(figure \@ref(fig:wflow-wrangle)). Section \@ref(sec:tidygranges)
introduces a grammar-based framework for transforming genomics data that is 
described in chapter \@ref(ch:plyranges). We then look at integrating data and 
model outputs over genomic regions to gain biological insight (\@ref(fig:wflow-integrate)). Section \@ref(sec:integrate) introduces a 
framework for incorporating genomic regions  over multiple assays, described in 
chapter \@ref(ch:fluentGenomics), while  \@ref(sec:coverage) discusses finding 'interesting' genomic regions via combining multiple summaries of a single assay, described in \@ref(ch:intron). Next, we 
consider the challenges in  visualising  high dimensional data (figure \@ref(fig:wflow-explore)). Section  \@ref(sec:va) introduces an interactive 
visualisation approach for  understanding non-linear dimension reduction 
techniques described in chapter  \@ref(ch:tsne). Lastly, in 
chapter \@ref(ch:conclusion) describes the outputs of the thesis and plans for future developments. 

## A grammar for genomic data analysis {#sec:tidygranges}

```{r wflow-wrangle, fig.cap="(ref:wflow-wrangle)"}
knitr::include_graphics(here::here("img", "wflow-thesis-wrangle.png"))
```

The approach taken by the suite of software packages collectively known as the 
**tidyverse**  is an attempt to formalise aspects of the EDA process in the R
programming language under a single semantic known as *tidy data* 
[@r-core; @tidyverse; @Wickham2014-jc]. Simply put, a *tidy data* set is a 
rectangular table where each row of the table corresponds to an observation, 
each column corresponds to a variable and each cell a value. There is a 
surprisingly large amount of utility that can be achieved with this definition. 
By having each column representing a variable, variables in the data can be 
mapped to graphical aesthetics of plots. This paradigm enables the grammar of graphics as implemented by **ggplot2** [@Wickham2016-gz; @Wilkinson2005-kq]. User interfaces as implemented by **tidyverse**, and in particular the **dplyr** package, are *fluent*;  they form a domain specific language (DSL) that gives users a mental model for performing and composing common data transformation tasks 
[@Wickham2017-dplyr; @FowlerFluent].

It is unclear whether the *fluent* interfaces as implemented using the
*tidy data* framework can be more generally applied and useful
in fields such as high-throughput biology where domain specific semantics are 
required (figure \@ref(fig:wflow-wrangle)). This is particularly true in the Bioconductor ecosystem, where much 
thought has gone into the design of data structures that enable interoperability
between different tools, biological assays and analysis goals [@Huber2015-ei].

Chapter \@ref(ch:plyranges) shows that the *tidy data* semantic is applicable
to range-based genomics data and develops a *fluent* interface to transforming
it called **plyranges**. The software provides a framework to an assist
an analyst to compose queries on genomics datasets. This chapter has been 
published as @Lee2019.

## Integration of genomic data structures {#sec:integrate}

```{r wflow-integrate, fig.cap="(ref:wflow-integrate)"}
knitr::include_graphics(here::here("img", "wflow-thesis-integrate.png"))
```

It is rare that a biological data analysis will involve
a single measurement assay or that only one aspect of a measurement assay
will be of interest to the biological question under study (figure \@ref(fig:wflow-integrate)). While there are 
many approaches to integrating data sets from multiple assays using multivariate
statistical techniques [@Meng2016-pz], in chapter \@ref(ch:fluentGenomics)
we describe a simple end-to-end workflow for integrating 
results along the genome using **plyranges**. This workflow also shows that
our grammar based approach does not impair interoperability between
the **tidyverse** and Bioconductor approaches, and in fact they work seamlessly
together. This chapter has been published as @Lee2020-ie. 

## Representation of genomic data structures{#sec:coverage}

In chapter \@ref(ch:intron) we explore the limits of the *tidy data*
semantic by extending **plyranges** to analyse coverage estimated on RNA-seq
data by developing a new software tool called **superintronic**. We show that the
long-form tidy representation is an effective way of combining the experimental
design and reference annotations into a single genomic data structure for
exploration. We use **superintronic** to develop a framework for discovering
interesting regions of coverage and apply our approach to integrating intron
signal from RNA-seq data. This chapter is based on my software and analysis
contributions to the preprint @Lee2019-mf. 

## Interactive visualisation for high-dimensional data {#sec:va}

```{r wflow-explore, fig.cap="(ref:wflow-explore)"}
knitr::include_graphics(here::here("img", "wflow-thesis-explore.png"))
```

In the final chapter, we move away from data wrangling and towards the 
integration of visualisation with model-based summaries of high-dimensional
data sets (figure \@ref(fig:wflow-explore)). We focus on a common tool for EDA 
(especially applied to single-cell transcriptomics): non-linear dimension 
reduction (NLDR). We consider the incorporation of interactive and dynamic 
graphics to assist analysts in using  NLDR techniques for cluster orientation 
tasks. In particular, we advocate  for the use of tours [@Cook1995-bi] alongside
an NLDR visualisation to  highlight potential pitfalls  and distortions obtained
from an NLDR method. This approach acknowledges that there is no 'one' best 
visualisation or dimension reduction for a high-dimensional dataset, and we 
often want to  have an understanding of both the global and local structure 
within our data.

Chapter \@ref(ch:tsne) introduces a software package called **liminal** for 
constructing these views and a user interaction framework for identifying 
distortions. We present several case studies using data that capture aspects of
single cell transcriptomics workflows, and use our approach to diagnose the
quality of results obtained  via popular NLDR methods like t-distributed 
stochastic neighbour embeddings (t-SNE) [@Maaten2008-sk].
