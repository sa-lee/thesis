<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.2 Overview of Dimension Reduction | Fluent statistical computing interfaces for biological data analysis</title>
  <meta name="description" content="5.2 Overview of Dimension Reduction | Fluent statistical computing interfaces for biological data analysis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="5.2 Overview of Dimension Reduction | Fluent statistical computing interfaces for biological data analysis" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.2 Overview of Dimension Reduction | Fluent statistical computing interfaces for biological data analysis" />
  
  
  

<meta name="author" content="Stuart Lee" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="5-1-introduction-2.html"/>
<link rel="next" href="5-3-visual-design.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="template/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./"></a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-ch-intro.html"><a href="1-ch-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="1-1-sec-tidygranges.html"><a href="1-1-sec-tidygranges.html"><i class="fa fa-check"></i><b>1.1</b> A grammar for genomic data analysis</a></li>
<li class="chapter" data-level="1.2" data-path="1-2-sec-integrate.html"><a href="1-2-sec-integrate.html"><i class="fa fa-check"></i><b>1.2</b> Integration of genomic data structures</a></li>
<li class="chapter" data-level="1.3" data-path="1-3-sec-coverage.html"><a href="1-3-sec-coverage.html"><i class="fa fa-check"></i><b>1.3</b> Representation of genomic data structures</a></li>
<li class="chapter" data-level="1.4" data-path="1-4-sec-va.html"><a href="1-4-sec-va.html"><i class="fa fa-check"></i><b>1.4</b> Interactive visualisation for high-dimensional data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-ch-plyranges.html"><a href="2-ch-plyranges.html"><i class="fa fa-check"></i><b>2</b> plyranges: a grammar of data transformation for genomics</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-background.html"><a href="2-1-background.html"><i class="fa fa-check"></i><b>2.1</b> Background</a></li>
<li class="chapter" data-level="2.2" data-path="2-2-results.html"><a href="2-2-results.html"><i class="fa fa-check"></i><b>2.2</b> Results</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-2-results.html"><a href="2-2-results.html#genomic-relational-algebra"><i class="fa fa-check"></i><b>2.2.1</b> Genomic Relational Algebra</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-2-results.html"><a href="2-2-results.html#developing-workflows-with-plyranges"><i class="fa fa-check"></i><b>2.2.2</b> Developing workflows with <strong>plyranges</strong></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-3-discussion.html"><a href="2-3-discussion.html"><i class="fa fa-check"></i><b>2.3</b> Discussion</a></li>
<li class="chapter" data-level="2.4" data-path="2-4-conclusion.html"><a href="2-4-conclusion.html"><i class="fa fa-check"></i><b>2.4</b> Conclusion</a></li>
<li class="chapter" data-level="2.5" data-path="2-5-availability-of-data-and-materials.html"><a href="2-5-availability-of-data-and-materials.html"><i class="fa fa-check"></i><b>2.5</b> Availability of Data and Materials</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-1.html"><a href="acknowledgements-1.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-ch-fluentGenomics.html"><a href="3-ch-fluentGenomics.html"><i class="fa fa-check"></i><b>3</b> Fluent genomics with <strong>plyranges</strong> and <strong>tximeta</strong></a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-introduction.html"><a href="3-1-introduction.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-1-introduction.html"><a href="3-1-introduction.html#experimental-data"><i class="fa fa-check"></i><b>3.1.1</b> Experimental Data</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-2-se.html"><a href="3-2-se.html"><i class="fa fa-check"></i><b>3.2</b> Import Data as a <em>SummarizedExperiment</em></a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-2-se.html"><a href="3-2-se.html#using-tximeta-to-import-rna-seq-quantification-data"><i class="fa fa-check"></i><b>3.2.1</b> Using <strong>tximeta</strong> to import RNA-seq quantification data</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-2-se.html"><a href="3-2-se.html#atac"><i class="fa fa-check"></i><b>3.2.2</b> Importing ATAC-seq data as a <em>SummarizedExperiment</em> object</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-3-model-assays.html"><a href="3-3-model-assays.html"><i class="fa fa-check"></i><b>3.3</b> Model assays</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-3-model-assays.html"><a href="3-3-model-assays.html#rna-seq-differential-gene-expression-analysis"><i class="fa fa-check"></i><b>3.3.1</b> RNA-seq differential gene expression analysis</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-3-model-assays.html"><a href="3-3-model-assays.html#atac-seq-peak-differential-abundance-analysis"><i class="fa fa-check"></i><b>3.3.2</b> ATAC-seq peak differential abundance analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-4-integrate-ranges.html"><a href="3-4-integrate-ranges.html"><i class="fa fa-check"></i><b>3.4</b> Integrate ranges</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-4-integrate-ranges.html"><a href="3-4-integrate-ranges.html#finding-overlaps-with-plyranges"><i class="fa fa-check"></i><b>3.4.1</b> Finding overlaps with <strong>plyranges</strong></a></li>
<li class="chapter" data-level="3.4.2" data-path="3-4-integrate-ranges.html"><a href="3-4-integrate-ranges.html#down-sampling-non-differentially-expressed-genes"><i class="fa fa-check"></i><b>3.4.2</b> Down sampling non-differentially expressed genes</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-4-integrate-ranges.html"><a href="3-4-integrate-ranges.html#expanding-genomic-coordinates-around-the-transcription-start-site"><i class="fa fa-check"></i><b>3.4.3</b> Expanding genomic coordinates around the transcription start site</a></li>
<li class="chapter" data-level="3.4.4" data-path="3-4-integrate-ranges.html"><a href="3-4-integrate-ranges.html#use-overlap-joins-to-find-relative-enrichment"><i class="fa fa-check"></i><b>3.4.4</b> Use overlap joins to find relative enrichment</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-5-discussion-1.html"><a href="3-5-discussion-1.html"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
<li class="chapter" data-level="3.6" data-path="3-6-software-availability.html"><a href="3-6-software-availability.html"><i class="fa fa-check"></i><b>3.6</b> Software Availability</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-2.html"><a href="acknowledgements-2.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch-intron.html"><a href="4-ch-intron.html"><i class="fa fa-check"></i><b>4</b> Exploratory coverage analysis with superintronic and plyranges</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-introduction-1.html"><a href="4-1-introduction-1.html"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="4-2-methods.html"><a href="4-2-methods.html"><i class="fa fa-check"></i><b>4.2</b> Methods</a><ul>
<li class="chapter" data-level="4.2.1" data-path="4-2-methods.html"><a href="4-2-methods.html#representation-of-coverage-estimation"><i class="fa fa-check"></i><b>4.2.1</b> Representation of coverage estimation</a></li>
<li class="chapter" data-level="4.2.2" data-path="4-2-methods.html"><a href="4-2-methods.html#integration-of-external-annotations"><i class="fa fa-check"></i><b>4.2.2</b> Integration of external annotations</a></li>
<li class="chapter" data-level="4.2.3" data-path="4-2-methods.html"><a href="4-2-methods.html#discovery-of-regions-of-interest-via-data-descriptors"><i class="fa fa-check"></i><b>4.2.3</b> Discovery of regions of interest via ‘data descriptors’</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-a-workflow-for-uncovering-intron-retention-in-a-zebrafish-experiment.html"><a href="4-3-a-workflow-for-uncovering-intron-retention-in-a-zebrafish-experiment.html"><i class="fa fa-check"></i><b>4.3</b> A workflow for uncovering intron retention in a zebrafish experiment</a></li>
<li class="chapter" data-level="4.4" data-path="4-4-discussion-2.html"><a href="4-4-discussion-2.html"><i class="fa fa-check"></i><b>4.4</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-3.html"><a href="acknowledgements-3.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-ch-tsne.html"><a href="5-ch-tsne.html"><i class="fa fa-check"></i><b>5</b> Casting multiple shadows: high-dimensional interactive data visualisation with tours and embeddings</a><ul>
<li class="chapter" data-level="5.1" data-path="5-1-introduction-2.html"><a href="5-1-introduction-2.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="5-2-overview-of-dimension-reduction.html"><a href="5-2-overview-of-dimension-reduction.html"><i class="fa fa-check"></i><b>5.2</b> Overview of Dimension Reduction</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-2-overview-of-dimension-reduction.html"><a href="5-2-overview-of-dimension-reduction.html#tours-explore-the-subspace-of-d-dimensional-projections"><i class="fa fa-check"></i><b>5.2.1</b> Tours explore the subspace of <span class="math inline">\(d\)</span>-dimensional projections</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-3-visual-design.html"><a href="5-3-visual-design.html"><i class="fa fa-check"></i><b>5.3</b> Visual Design</a><ul>
<li class="chapter" data-level="5.3.1" data-path="5-3-visual-design.html"><a href="5-3-visual-design.html#finding-gestalt-focus-and-context"><i class="fa fa-check"></i><b>5.3.1</b> Finding Gestalt: focus and context</a></li>
<li class="chapter" data-level="5.3.2" data-path="5-3-visual-design.html"><a href="5-3-visual-design.html#posing-queries-multiple-views-many-contexts"><i class="fa fa-check"></i><b>5.3.2</b> Posing Queries: multiple views, many contexts</a></li>
<li class="chapter" data-level="5.3.3" data-path="5-3-visual-design.html"><a href="5-3-visual-design.html#making-comparisons-revising-embeddings"><i class="fa fa-check"></i><b>5.3.3</b> Making comparisons: revising embeddings</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5-4-software-infrastructure.html"><a href="5-4-software-infrastructure.html"><i class="fa fa-check"></i><b>5.4</b> Software Infrastructure</a><ul>
<li class="chapter" data-level="5.4.1" data-path="5-4-software-infrastructure.html"><a href="5-4-software-infrastructure.html#tours-as-a-streaming-data-problem"><i class="fa fa-check"></i><b>5.4.1</b> Tours as a streaming data problem</a></li>
<li class="chapter" data-level="5.4.2" data-path="5-4-software-infrastructure.html"><a href="5-4-software-infrastructure.html#linking-and-highlighting-views-via-interactions"><i class="fa fa-check"></i><b>5.4.2</b> Linking and highlighting views via interactions</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5-5-case-studies.html"><a href="5-5-case-studies.html"><i class="fa fa-check"></i><b>5.5</b> Case Studies</a><ul>
<li class="chapter" data-level="5.5.1" data-path="5-5-case-studies.html"><a href="5-5-case-studies.html#case-study-1-exploring-spherical-gaussian-clusters"><i class="fa fa-check"></i><b>5.5.1</b> Case Study 1: Exploring spherical Gaussian clusters</a></li>
<li class="chapter" data-level="5.5.2" data-path="5-5-case-studies.html"><a href="5-5-case-studies.html#case-study-2-exploring-spherical-gaussian-clusters-with-hierarchical-structure"><i class="fa fa-check"></i><b>5.5.2</b> Case Study 2: Exploring spherical Gaussian clusters with hierarchical structure</a></li>
<li class="chapter" data-level="5.5.3" data-path="5-5-case-studies.html"><a href="5-5-case-studies.html#case-study-3-exploring-data-with-piecewise-linear-structure"><i class="fa fa-check"></i><b>5.5.3</b> Case Study 3: Exploring data with piecewise linear structure</a></li>
<li class="chapter" data-level="5.5.4" data-path="5-5-case-studies.html"><a href="5-5-case-studies.html#case-study-4-clustering-single-cell-rna-seq-data"><i class="fa fa-check"></i><b>5.5.4</b> Case Study 4: Clustering single cell RNA-seq data</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="5-6-discussion-3.html"><a href="5-6-discussion-3.html"><i class="fa fa-check"></i><b>5.6</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="acknowledgements-4.html"><a href="acknowledgements-4.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="supplementary-materials.html"><a href="supplementary-materials.html"><i class="fa fa-check"></i>Supplementary Materials</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-ch-conclusion.html"><a href="6-ch-conclusion.html"><i class="fa fa-check"></i><b>6</b> Conclusion</a><ul>
<li class="chapter" data-level="6.1" data-path="6-1-software-development.html"><a href="6-1-software-development.html"><i class="fa fa-check"></i><b>6.1</b> Software Development</a></li>
<li class="chapter" data-level="6.2" data-path="6-2-further-work.html"><a href="6-2-further-work.html"><i class="fa fa-check"></i><b>6.2</b> Further Work</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><strong><a href="https://github.com/rstudio/bookdown" target="blank">Proudly published with bookdown</a></strong></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fluent statistical computing interfaces for biological data analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="overview-of-dimension-reduction" class="section level2">
<h2><span class="header-section-number">5.2</span> Overview of Dimension Reduction</h2>
<p>In the following section, we provide a brief overview of the goals of DR
methods with respect to the data analyst, in addition to their high level the
mathematical details. Here we restrict our attention to two recent methods that
are commonly used in the literature: t-distributed stochastic neighbour embedding
(t-SNE) and uniform manifold alignment and projection (UMAP); however we do
mention several other techniques <span class="citation">(Maaten and Hinton <a href="bibliography.html#ref-Maaten2008-sk" role="doc-biblioref">2008</a>; McInnes, Healy, and Melville <a href="bibliography.html#ref-McInnes2018-co" role="doc-biblioref">2018</a>)</span>.</p>
<p>To begin we suppose the data is in the form rectangular
matrix of real numbers, <span class="math inline">\(X = [\mathbf{x_1}, \dots, \mathbf{x_n}]\)</span>, where <span class="math inline">\(n\)</span> is
the number of observations in <span class="math inline">\(p\)</span> dimensions. The purpose of any DR algorithm
is to find a low-dimensional representation of the data,
<span class="math inline">\(Y = [\mathbf{y_1}, \dots, \mathbf{y_n}]\)</span>, such that <span class="math inline">\(Y\)</span> is an <span class="math inline">\(n \times d\)</span>
matrix where <span class="math inline">\(d \ll p\)</span>. The hope of the analyst is that the DR procedure to
produces <span class="math inline">\(Y\)</span> will remove noise in the original dataset while retaining any
latent structure.</p>
<p>DR methods can be classified into two broad classes: linear and non-linear
methods. Linear methods perform a linear transformation of the data, that is,
<span class="math inline">\(Y\)</span> is a linear transformation of <span class="math inline">\(X\)</span>; one example is principal components
analysis (PCA) which performs an eigendecomposition of the estimated sample
covariance matrix. The eigenvalues are sorted in decreasing order and represent
the variance explained by each component (eigenvector).
A common approach to deciding on the number of principal components to retain is
to plot the proportion of variance explained by each component and choose a
cut-off.</p>
<p>For non-linear methods <span class="math inline">\(Y\)</span> is generated via a pre-processed form of the input
<span class="math inline">\(X\)</span> such as the <span class="math inline">\(k\)</span>-nearest neighbours graph or via a kernel transformation.
Multidimensional scaling (MDS) is a class of DR method that aims to construct
an embedding <span class="math inline">\(Y\)</span> such that the pair-wise distances (inner products) in <span class="math inline">\(Y\)</span>
approximate the pair-wise distances (inner products) in <span class="math inline">\(X\)</span>
<span class="citation">(Torgerson <a href="bibliography.html#ref-Torgerson1952-am" role="doc-biblioref">1952</a>; Kruskal <a href="bibliography.html#ref-Kruskal1964-cz" role="doc-biblioref">1964</a><a href="bibliography.html#ref-Kruskal1964-cz" role="doc-biblioref">a</a>)</span>. There are many
variants of MDS, such as non-metric scaling which amounts to replacing
distances with ranks instead <span class="citation">(Kruskal <a href="bibliography.html#ref-Kruskal1964-cw" role="doc-biblioref">1964</a><a href="bibliography.html#ref-Kruskal1964-cw" role="doc-biblioref">b</a>)</span>.
A related technique is Isomap which uses a <span class="math inline">\(k\)</span>-nearest neighbour graph
to estimate the pair-wise geodesic distance of points in <span class="math inline">\(X\)</span> then uses classical
MDS to construct <span class="math inline">\(Y\)</span> <span class="citation">(Silva and Tenenbaum <a href="bibliography.html#ref-Silva2003-xw" role="doc-biblioref">2003</a>)</span>. Other approaches are based on diffusion
processes such as diffusion maps <span class="citation">(Coifman et al. <a href="bibliography.html#ref-Coifman2005-ak" role="doc-biblioref">2005</a>)</span>. A recent example of this
approach is the PHATE algorithm <span class="citation">(Moon et al. <a href="bibliography.html#ref-Moon2019-ce" role="doc-biblioref">2019</a>)</span>. Here an affinity matrix is
estimated via the pair-wise distance matrix and k-nearest neighbours graph of <span class="math inline">\(X\)</span>.
The algorithm de-noises estimated distances in high-dimensional space via
transforming the affinity matrix into a Markov transition probability matrix
and diffusing this matrix over a fixed number of time steps. Then the diffused
probabilities are transformed once more to construct a distance matrix,
and classical MDS is used to generate <span class="math inline">\(Y\)</span>. A general difficulty with using
non-linear DR methods for exploratory data analysis is selecting and tuning
appropriate parameters. To see the extent of these choices
we now examine the underpinnings of t-SNE and UMAP.</p>
<p>The t-SNE algorithm estimates
the pair-wise similarity of (Euclidean) distances of points in a high
dimensional space using a Gaussian distribution and then estimates a
configuration in the low dimensional embedding space by modelling similarities
using a t-distribution with 1 degree of freedom <span class="citation">(Maaten and Hinton <a href="bibliography.html#ref-Maaten2008-sk" role="doc-biblioref">2008</a>)</span>. There are several subtleties
to the to use of the algorithm that are revealed by stepping through its
machinery.</p>
<p>To begin, t-SNE transforms pair-wise distances between <span class="math inline">\(\mathbf{x_i}\)</span> and
<span class="math inline">\(\mathbf{x_j}\)</span> to similarities using a Gaussian kernel:</p>
<p><span class="math display">\[ p_{i|j} = \frac{\exp(-\lVert \mathbf{x_i - x_j} \rVert ^ 2 /
2\sigma_i^2)}{\sum_{k \ne i}\exp(-\lVert \mathbf{x_j - x_k} \rVert ^ 2 /
2\sigma_i^2)} \]</span></p>
<p>The conditional probabilities are then normalised and symmetrised to form a
joint probability distribution via averaging:</p>
<p><span class="math display">\[ p_{ij} = \frac{p_{i|j} + p_{j|i}}{2n} \]</span></p>
<p>The variance parameter of the Gaussian kernel is controlled by the analyst
using a fixed value of perplexity for all observations:</p>
<p><span class="math display">\[ \text{perplexity}_i = \exp(-\log(2) \sum_{i \ne j}p_{j|i}\log_2(p_{j|i})) \]</span>
As the perplexity increases, <span class="math inline">\(\sigma^2_{i}\)</span> increases, until its bounded above
by the number of observations , <span class="math inline">\(n-1\)</span>, in the data, corresponding to
<span class="math inline">\(\sigma^2_{i} \rightarrow \infty\)</span>. This essentially turns <span class="math inline">\(t-SNE\)</span> into a
nearest neighbours algorithm, <span class="math inline">\(p_{i|j}\)</span> will be close to zero for all
observations that are not in the <span class="math inline">\(\mathcal{O}(\text{perplexity}_i)\)</span>
neighbourhood graph of the <span class="math inline">\(i\)</span>th observation <span class="citation">(Maaten <a href="bibliography.html#ref-Van_Der_Maaten2014-zn" role="doc-biblioref">2014</a>)</span>.</p>
<p>Next, the target low-dimensional space, <span class="math inline">\(Y\)</span>, pair-wise distances between
<span class="math inline">\(\mathbf{y_i}\)</span> and <span class="math inline">\(\mathbf{y_j}\)</span> are modelled as a symmetric probability
distribution using a t-distribution with one degree of freedom (Cauchy kernel):</p>
<p><span class="math display">\[ q_{ij} = \frac{w_{ij}}{Z} \\ \text{where } w_{ij} = \frac{1}{ 1 + \lVert
\mathbf{y_i - y_j} \rVert ^ 2} \text{ and } Z = \sum_{k \ne l} w_{kl}. \]</span></p>
<p>The resulting embedding <span class="math inline">\(Y\)</span> is the one that minimizes the Kullback-Leibler
divergence between the probability distributions formed via similarities of
observations in <span class="math inline">\(X\)</span>, <span class="math inline">\(\mathcal{P}\)</span> and similarities of observations in <span class="math inline">\(Y\)</span>,
<span class="math inline">\(\mathcal{Q}\)</span>:</p>
<p><span class="math display">\[ \mathcal{L(\mathcal{P}, \mathcal{Q})} = \sum_{i \ne j} p_{ij} \log
\frac{p_{ij}}{q_{ij}}\]</span></p>
<p>Re-writing the loss function in terms of attractive (right) and repulsive
(left) forces we obtain:</p>
<p><span class="math display">\[ \mathcal{L(\mathcal{P}, \mathcal{Q})} = -\sum_{i \ne j} p_{ij}\log w_{ij} +
\log\sum_{i \ne j} w_{ij} \]</span></p>
<p>So when the loss function is minimised this corresponds to large attractive
forces, that is, the pair-wise distances in <span class="math inline">\(Y\)</span> are small when there are
non-zero <span class="math inline">\(p_{ij}\)</span>, i.e. <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> are close together. The repulsive force
should also be small when the loss function is minimised, that is, when
pair-wise distances in <span class="math inline">\(Y\)</span> are large regardless of the magnitude of the
corresponding distances in <span class="math inline">\(X\)</span>.</p>
<p>Taken together, these details reveal the sheer number of decisions that an
analyst must make. How does one choose the perplexity? How should the
parameters that control the optimisation of the loss function (done with
stochastic gradient descent), like the number of iterations, or early
exaggeration ( a multiplier of the attractive force at the beginning of the
optimisation), or the learning rate be selected? It is a known problem that
t-SNE can have trouble recovering topology and that configurations can be
highly dependent on how the algorithm is initialised and parameterized
<span class="citation">(Wattenberg, Viégas, and Johnson <a href="bibliography.html#ref-Wattenberg2016-ji" role="doc-biblioref">2016</a>; Kobak and Berens <a href="bibliography.html#ref-Kobak2019-lm" role="doc-biblioref">2019</a>; Melville <a href="bibliography.html#ref-Melville2020" role="doc-biblioref">2020</a>)</span>. If the goal is cluster
orientation a recent theoretical contribution by <span class="citation">Linderman and Steinerberger (<a href="bibliography.html#ref-Linderman2019-dq" role="doc-biblioref">2019</a>)</span> proved that
t-SNE can recover spherical and well separated cluster shapes, and proposed new
approaches for tuning the optimisation parameters. However, the cluster sizes
and their relative orientation from a <span class="math inline">\(t-SNE\)</span> view can be misleading
perceptually, due to the algorithms emphasis on locality.</p>
<p>Another recent method, UMAP, has seen a large rise in popularity (at least in
single cell transcriptomics) <span class="citation">(McInnes, Healy, and Melville <a href="bibliography.html#ref-McInnes2018-co" role="doc-biblioref">2018</a>)</span>. It is a method that is related to
LargeVis <span class="citation">(Tang et al. <a href="bibliography.html#ref-Tang2016-oz" role="doc-biblioref">2016</a>)</span>, and like t-SNE acts on the k-nearest neighbour graph.
Its main differences are that it uses a different cost function (cross entropy)
which is optimized using stochastic gradient descent and defines a different
kernel for similarities in the low dimensional space. Due to its computational
speed it is possible to generate UMAP embeddings in more than three dimensions.
It appears to suffer from the same perceptual issues as t-SNE, however it supposedly preserves global structure better than t-SNE <span class="citation">(Coenen and Pearce <a href="bibliography.html#ref-Coenen2019-to" role="doc-biblioref">2019</a>)</span>.</p>
<div id="tours-explore-the-subspace-of-d-dimensional-projections" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Tours explore the subspace of <span class="math inline">\(d\)</span>-dimensional projections</h3>
<p>The tour is a visualisation technique that is grounded in
mathematical theory, and is able to ascertain
the shape and global structure of a dataset via inspection of the subspace generated by the set of low-dimensional projections <span class="citation">(Asimov <a href="bibliography.html#ref-Asimov1985-vp" role="doc-biblioref">1985</a>; Buja and Asimov <a href="bibliography.html#ref-Buja1986-zr" role="doc-biblioref">1986</a>)</span>.</p>
<p>Like, when, using other DR techniques, the tour assumes we have a real data matrix
<span class="math inline">\(X\)</span> consisting of <span class="math inline">\(n\)</span> observations in <span class="math inline">\(p\)</span> dimensions. First, the tour generates
a sequence of <span class="math inline">\(p \times d\)</span> orthonormal projection matrices (bases)
<span class="math inline">\(A_{t \in \mathbb{N}}\)</span>, where <span class="math inline">\(d\)</span> is typically <span class="math inline">\(1\)</span> or <span class="math inline">\(2\)</span>. For each pair of
orthonormal bases <span class="math inline">\(A_{t}\)</span> and <span class="math inline">\(A_{t+1}\)</span> that are generated, the geodesic
path between them is interpolated to form intermediate frames, and giving the
sense of continuous movement from one basis to another. The tour is then the
continuous visualisation of the projections <span class="math inline">\(Y_{t} = XA_{t}\)</span>, that is the
projection of <span class="math inline">\(X\)</span> onto <span class="math inline">\(A_{t}\)</span> as the tour path is interpolated between
successive bases. A <em>grand tour</em> corresponds to choosing new orthonormal
bases at random; allowing a user to ascertain structure via exploring the
subspace of <span class="math inline">\(d\)</span>-dimensional projections. In practice, we first sphere
our data via principal components to reduce dimensionality of <span class="math inline">\(X\)</span> prior to
running the tour. Instead of picking projections at
random, a <em>guided tour</em> can be used to generate a sequence of ‘interesting’
projections as quantified by an index function <span class="citation">(Cook et al. <a href="bibliography.html#ref-Cook1995-bi" role="doc-biblioref">1995</a>)</span>. While our software,
<strong>liminal</strong> is able to visualise guided tours, our focus in the case studies
uses the grand tour to see global structure in the data.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="5-1-introduction-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="5-3-visual-design.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sa-lee/thesis/edit/master/Rmd//05-embeddings.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
