% misc references for intro and discussion sections


@MISC{FowlerFluent,
  title        = "{FluentInterface}",
  booktitle    = "martinfowler.com",
  author       = "Fowler, Martin",
  abstract     = "A fluent interface is a way of building an API so that its
                  use has the feel of an internal domain-specific language.",
  url          = "https://martinfowler.com/bliki/FluentInterface.html",
  howpublished = "\url{https://martinfowler.com/bliki/FluentInterface.html}",
  note         = "Accessed: 2020-2-23"
}


@BOOK{Tukey1977-pn,
  title     = "Exploratory data analysis",
  author    = "Tukey, John W",
  publisher = "Reading, Mass.: Addison-Wesley Pub. Co",
  volume    =  2,
  year      =  1977
}

@Manual{ggally,
    title = {GGally: Extension to 'ggplot2'},
    author = {Barret Schloerke and Jason Crowley and Di Cook and Francois Briatte and Moritz Marbach and Edwin Thoen and Amos Elberg and Joseph Larmarange},
    year = {2020},
    note = {R package version 1.5.0},
    url = {https://CRAN.R-project.org/package=GGally},
  }


@BOOK{Wilkinson2005-kq,
  title     = "The Grammar of Graphics",
  author    = "Wilkinson, Leland",
  abstract  = "Preface to First Edition Before writing the graphics for SYSTAT
               in the 1980's, I began by teaching a seminar in statistical
               graphics and collecting as many different quantitative graphics
               as I could find. I was determined to produce a package that
               could draw every statistical graphic I had ever seen. The
               structure of the program was a collection of procedures named
               after the basic graph types they p- duced. The graphics code was
               roughly one and a half megabytes in size. In the early 1990's, I
               redesigned the SYSTAT graphics package using - ject-based
               technology. I intended to produce a more comprehensive and -
               namic package. I accomplished this by embedding graphical
               elements in a tree structure. Rendering graphics was done by
               walking the tree and editing worked by adding and deleting
               nodes. The code size fell to under a megabyte. In the late
               1990's, I collaborated with Dan Rope at the Bureau of Labor
               Statistics and Dan Carr at George Mason University to produce a
               graphics p- duction library called GPL, this time in Java. Our
               goal was to develop graphics components. This book was nourished
               by that project. So far, the GPL code size is under half a
               megabyte.",
  publisher = "Springer Science \& Business Media",
  series    = "Statistics and Computing",
  month     =  jul,
  year      =  2005,
  url       = "https://market.android.com/details?id=book-_kRX4LoFfGQC",
  isbn      = "9780387245447, 9780387286952",
  doi       = "10.1007/0-387-28695-0"
}



@BOOK{Wickham2016-gz,
  title     = "ggplot2: Elegant Graphics for Data Analysis",
  author    = "Wickham, Hadley",
  abstract  = "This new edition to the classic book by ggplot2 creator Hadley
               Wickham highlights compatibility with knitr and RStudio. ggplot2
               is a data visualization package for R that helps users create
               data graphics, including those that are multi-layered, with
               ease. With ggplot2, it's easy to: produce handsome,
               publication-quality plots with automatic legends created from
               the plot specificationsuperimpose multiple layers (points,
               lines, maps, tiles, box plots) from different data sources with
               automatically adjusted common scalesadd customizable smoothers
               that use powerful modeling capabilities of R, such as loess,
               linear models, generalized additive models, and robust
               regressionsave any ggplot2 plot (or part thereof) for later
               modification or reusecreate custom themes that capture in-house
               or journal style requirements and that can easily be applied to
               multiple plotsapproach a graph from a visual perspective,
               thinking about how each component of the data is represented on
               the final plot This book will be useful to everyone who has
               struggled with displaying data in an informative and attractive
               way. Some basic knowledge of R is necessary (e.g., importing
               data into R). ggplot2 is a mini-language specifically tailored
               for producing graphics, and you'll learn everything you need in
               the book. After reading this book you'll be able to produce
               graphics customized precisely for your problems, and you'll find
               it easy to get graphics out of your head and on to the screen or
               page.",
  publisher = "Springer International Publishing",
  series    = "Use R!",
  month     =  jun,
  year      =  2016,
  url       = "https://play.google.com/store/books/details?id=RTMFswEACAAJ",
  isbn      = "9783319242750, 9783319242774",
  doi       = "10.1007/978-3-319-24277-4"
}


@BOOK{Grolemund2017-uc,
  title    = "{R} for Data Science",
  author   = "Grolemund, Garrett and Wickham, Hadley",
  abstract = "This book will teach you how to do data science with R: You'll
              learn how to get your data into R, get it into the most useful
              structure, transform it, visualise it and model it. In this book,
              you will find a practicum of skills for data science. Just as a
              chemist learns how to clean test tubes and stock a lab, you'll
              learn how to clean data and draw plots---and many other things
              besides. These are the skills that allow data science to happen,
              and here you will find the best practices for doing each of these
              things with R. You'll learn how to use the grammar of graphics,
              literate programming, and reproducible research to save time.
              You'll also learn how to manage cognitive resources to facilitate
              discoveries when wrangling, visualising, and exploring data.",
  pages    = "89",
  year     =  2017,
  url      = "http://r4ds.had.co.nz/"
}


@Book{bookdown,
  title = {bookdown: Authoring Books and Technical Documents with {R}
    Markdown},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2016},
  note = {ISBN 978-1138700109},
  url = {https://github.com/rstudio/bookdown},
}



@Manual{renv,
  title = {renv: Project Environments},
  author = {Kevin Ushey},
  year = {2019},
  note = {R package version 0.7.0-54},
  url = {https://rstudio.github.io/renv},
}


@ARTICLE{Meng2016-pz,
  title    = "Dimension reduction techniques for the integrative analysis of
              multi-omics data",
  author   = "Meng, Chen and Zeleznik, Oana A and Thallinger, Gerhard G and
              Kuster, Bernhard and Gholami, Amin M and Culhane, Aed{\'\i}n C",
  abstract = "State-of-the-art next-generation sequencing, transcriptomics,
              proteomics and other high-throughput 'omics' technologies enable
              the efficient generation of large experimental data sets. These
              data may yield unprecedented knowledge about molecular pathways
              in cells and their role in disease. Dimension reduction
              approaches have been widely used in exploratory analysis of
              single omics data sets. This review will focus on dimension
              reduction approaches for simultaneous exploratory analyses of
              multiple data sets. These methods extract the linear
              relationships that best explain the correlated structure across
              data sets, the variability both within and between variables (or
              observations) and may highlight data issues such as batch effects
              or outliers. We explore dimension reduction techniques as one of
              the emerging approaches for data integration, and how these can
              be applied to increase our understanding of biological systems in
              normal physiological function and disease.",
  journal  = "Brief. Bioinform.",
  volume   =  17,
  number   =  4,
  pages    = "628--641",
  month    =  jul,
  year     =  2016,
  url      = "http://dx.doi.org/10.1093/bib/bbv108",
  keywords = "dimension reduction; exploratory data analysis; integrative
              genomics; multi-assay; multi-omics data integration; multivariate
              analysis",
  issn     = "1467-5463, 1477-4054",
  pmid     = "26969681",
  doi      = "10.1093/bib/bbv108",
  pmc      = "PMC4945831"
}


@ARTICLE{Laa2020-wr,
  title         = "Hole or grain? A Section Pursuit Index for Finding Hidden
                   Structure in Multiple Dimensions",
  author        = "Laa, Ursula and Cook, Dianne and Buja, Andreas and Valencia,
                   German",
  abstract      = "Multivariate data is often visualized using linear
                   projections, produced by techniques such as principal
                   component analysis, linear discriminant analysis, and
                   projection pursuit. A problem with projections is that they
                   obscure low and high density regions near the center of the
                   distribution. Sections, or slices, can help to reveal them.
                   This paper develops a section pursuit method, building on
                   the extensive work in projection pursuit, to search for
                   interesting slices of the data. Linear projections are used
                   to define sections of the parameter space, and to calculate
                   interestingness by comparing the distribution of
                   observations, inside and outside a section. By optimizing
                   this index, it is possible to reveal features such as holes
                   (low density) or grains (high density). The optimization is
                   incorporated into a guided tour so that the search for
                   structure can be dynamic. The approach can be useful for
                   problems when data distributions depart from uniform or
                   normal, as in visually exploring nonlinear manifolds, and
                   functions in multivariate space. Two applications of section
                   pursuit are shown: exploring decision boundaries from
                   classification models, and exploring subspaces induced by
                   complex inequality conditions from multiple parameter model.
                   The new methods are available in R, in the tourr package.",
  month         =  apr,
  year          =  2020,
  url           = "http://arxiv.org/abs/2004.13327",
  archivePrefix = "arXiv",
  eprint        = "2004.13327",
  primaryClass  = "stat.CO",
  arxivid       = "2004.13327"
}


@ARTICLE{Laa2020-fy,
  title     = "A slice tour for finding hollowness in high-dimensional data",
  author    = "Laa, Ursula and Cook, Dianne and Valencia, German",
  abstract  = "AbstractTaking projections of high-dimensional data is a common
               analytical and visualisation technique in statistics for working
               with high-dimensional problems. Sectioning, or slicing, through
               high dimensions is less common, but can be useful for
               visualising data with concavities, or non-linear structure. It
               is associated with conditional distributions in statistics, and
               also linked brushing between plots in interactive data
               visualisation. This short technical note describes a simple
               approach for slicing in the orthogonal space of projections
               obtained when running a tour, thus presenting the viewer with an
               interpolated sequence of sliced projections. The method has been
               implemented in R as an extension to the tourr package, and can
               be used to explore for concave and non-linear structures in
               multivariate distributions.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  pages     = "1--10",
  month     =  jun,
  year      =  2020,
  url       = "https://doi.org/10.1080/10618600.2020.1777140",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.2020.1777140"
}



@BOOK{Xie2016-oa,
  title     = "bookdown: Authoring Books and Technical Documents with {R}
               Markdown",
  author    = "Xie, Yihui",
  abstract  = "bookdown: Authoring Books and Technical Documents with R
               Markdown presents a much easier way to write books and technical
               publications than traditional tools such as LaTeX and Word. The
               bookdown package inherits the simplicity of syntax and
               flexibility for data analysis from R Markdown, and extends R
               Markdown for technical writing, so that you can make better use
               of document elements such as figures, tables, equations,
               theorems, citations, and references. Similar to LaTeX, you can
               number and cross-reference these elements with bookdown. Your
               document can even include live examples so readers can interact
               with them while reading the book. The book can be rendered to
               multiple output formats, including LaTeX/PDF, HTML, EPUB, and
               Word, thus making it easy to put your documents online. The
               style and theme of these output formats can be customized. We
               used books and R primarily for examples in this book, but
               bookdown is not only for books or R. Most features introduced in
               this book also apply to other types of publications: journal
               papers, reports, dissertations, course handouts, study notes,
               and even novels. You do not have to use R, either. Other choices
               of computing languages include Python, C, C++, SQL, Bash, Stan,
               JavaScript, and so on, although R is best supported. You can
               also leave out computing, for example, to write a fiction. This
               book itself is an example of publishing with bookdown and R
               Markdown, and its source is fully available on GitHub.",
  publisher = "CRC Press",
  month     =  dec,
  year      =  2016,
  url       = "https://play.google.com/store/books/details?id=8nm0DQAAQBAJ",
  isbn      = "9781351792608"
}

@BOOK{Xie2017-ke,
  title     = "Dynamic Documents with {R} and knitr",
  author    = "Xie, Yihui",
  abstract  = "Quickly and Easily Write Dynamic Documents Suitable for both
               beginners and advanced users, Dynamic Documents with R and
               knitr, Second Edition makes writing",
  publisher = "Chapman and Hall/CRC",
  month     =  jul,
  year      =  2017,
  url       = "https://www.taylorfrancis.com/books/9781315382487",
  isbn      = "9781315382487, 9781315382487",
  doi       = "10.1201/9781315382487"
}


@UNPUBLISHED{Lee2019-mf,
  title    = "Covering all your bases: incorporating intron signal from
              {RNA-seq} data",
  author   = "Lee, Stuart and Zhang, Albert Y and Su, Shian and Ng, Ashley P
              and Holik, Aliaksei Z and Asselin-Labat, Marie-Liesse and
              Ritchie, Matthew E and Law, Charity W",
  abstract = "RNA-seq datasets can contain millions of intron reads per
              sequenced library that are typically removed from downstream
              analysis. Only reads overlapping annotated exons are considered
              to be informative since mature mRNA is assumed to be the major
              component sequenced, especially when examining poly(A) RNA
              samples. In this paper, we demonstrate that intron reads are
              informative and that pre-mRNA is the major source of intron
              signal. Making use of pre-mRNA signal, our index method combines
              differential expression analyses from intron and exon counts to
              categorise changes observed in each count set, giving additional
              genes with evidence of transcriptional changes when compared to a
              classic approach. Considering the importance of intron retention
              in some biological systems, another novel method, superintronic,
              looks for evidence of intron retention after accounting for the
              presence of pre-mRNA signal. The results presented here overcomes
              deficiencies and biases in previous works related to intron reads
              by exploring multiple sources for intron reads simultaneously
              using a data-driven approach, and provides a broad overview into
              how intron reads can be utilised in relation to multiple aspects
              of transcriptional biology.",
  journal  = "bioRxiv",
  pages    = "352823",
  month    =  jul,
  year     =  2019,
  url      = "https://www.biorxiv.org/content/10.1101/352823v2",
  doi      = "10.1101/352823"
}


@Manual{renv,
    title = "renv: Project Environments",
    author = "Ushey, Kevin",
    year = 2020,
    note = "R package version 0.11.0",
    url = "https://CRAN.R-project.org/package=renv",
}

